{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2941c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c6a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting Data\n",
    "url = \"http://shakespeare.mit.edu/\"  # Here I use an online text source which is like the Project Gutenberg dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ed7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4217e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ea3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "link1 = [url + link['href'] for link in links if link['href'].endswith('.html')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0705ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making A Function To Extracting Text.\n",
    "def text_play(play_url):\n",
    "    play_response = requests.get(play_url)\n",
    "    play_soup = BeautifulSoup(play_response.content, 'html.parser')\n",
    "    play_text = play_soup.get_text()\n",
    "    return play_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d345b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from all plays\n",
    "all_texts = []\n",
    "for link1 in link1:\n",
    "    all_texts.append( text_play(link1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616113bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a single string by combine\n",
    "combined_text = ' '.join(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5573906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vkvis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # extracting text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d70c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the text into sentences and words\n",
    "sentences = sent_tokenize(combined_text)\n",
    "words = [word_tokenize(sentence) for sentence in sentences]\n",
    "words = [[word.lower() for word in sentence if word.isalpha()] for sentence in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a02677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vkvis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries and fuction to making model and train\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6b2019",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for sentence in words for word in sentence] #training\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_words)\n",
    "sequences = tokenizer.texts_to_sequences(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8dd126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87661e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(sequences, length):\n",
    "    X, y = [], []\n",
    "    for i in range(length, len(sequences)):\n",
    "        X.append(sequences[i-length:i])\n",
    "        y.append(sequences[i])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a6e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_sequences(sequences, sequence_length)\n",
    "X = tf.convert_to_tensor(X)\n",
    "y = tf.convert_to_tensor(to_categorical(y, num_classes=vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e3414fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vkvis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=sequence_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46601359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vkvis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\vkvis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vkvis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "154/154 [==============================] - 41s 235ms/step - loss: 7.1416 - accuracy: 0.0413\n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 33s 216ms/step - loss: 6.7038 - accuracy: 0.0442\n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 32s 210ms/step - loss: 6.5338 - accuracy: 0.0571\n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 32s 206ms/step - loss: 6.2853 - accuracy: 0.0708\n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 31s 201ms/step - loss: 6.0695 - accuracy: 0.0878\n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 31s 198ms/step - loss: 5.9417 - accuracy: 0.0909\n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 31s 200ms/step - loss: 5.8452 - accuracy: 0.0955\n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 30s 193ms/step - loss: 5.7618 - accuracy: 0.0998\n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 34s 219ms/step - loss: 5.6851 - accuracy: 0.1049\n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 32s 208ms/step - loss: 5.6176 - accuracy: 0.1088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24839c97490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting arranging and training the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=256) #Here I gave epochs = 10 because it will take less time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74113149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-10) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "707f3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text(model, tokenizer, seed_text, num_words, sequence_length, temperature=2.0):\n",
    "    for _ in range(num_words):\n",
    "        tlist = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        tlist = pad_sequences([tlist], maxlen=sequence_length, padding='pre')\n",
    "        predicted = model.predict(tlist, verbose=0)[0]\n",
    "        word_index = sample(predicted, temperature)\n",
    "        word = tokenizer.index_word.get(word_index, '')\n",
    "        seed_text += \" \" + word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcc0b983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to be made whose beauty is else to with be fall and his tide look with woe say for the stone would would come for with my heart and strife his garment but the bird doth to not talk o i up to his eyes his day of flatter whose painter do these in my fixed cxxvi of another field of you began and me her end of fearfully from till being comfortable pride and be yet the spectacle of frozen in i then like lives i more thou but he be give for let quoth this love hath my other still\n"
     ]
    }
   ],
   "source": [
    "# Now Generating text\n",
    "seed_text = \"To be or not to be\"\n",
    "text = text(model, tokenizer, seed_text, 100, sequence_length, temperature=0.7)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7d020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
